{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 4 – NLP Part 1\n",
        "\n",
        "BoW, TF-IDF und optional Embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mini-Korpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "docs = [\n",
        "    \"Katzen sind neugierige Tiere.\",\n",
        "    \"Hunde sind treue Tiere.\",\n",
        "    \"Ich lerne NLP und maschinelles Lernen.\",\n",
        "    \"NLP hilft, Textdaten zu analysieren.\",\n",
        "    \"Meine Katze schläft gerne.\",\n",
        "]\n",
        "docs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(docs)\n",
        "vocab = cv.get_feature_names_out()\n",
        "\n",
        "df_bow = pd.DataFrame(X.toarray(), columns=vocab)\n",
        "df_bow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tv = TfidfVectorizer()\n",
        "T = tv.fit_transform(docs)\n",
        "df_tfidf = pd.DataFrame(T.toarray(), columns=tv.get_feature_names_out())\n",
        "df_tfidf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Semantische Ähnlichkeit mit Satzvektoren (optional)\n",
        "\n",
        "Erfordert Modell-Download, daher am bequemsten auf Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Optional:\n",
        "# !pip -q install sentence-transformers\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "# emb = model.encode(docs, normalize_embeddings=True)\n",
        "# query = \"Textanalyse mit NLP\"\n",
        "# q = model.encode([query], normalize_embeddings=True)[0]\n",
        "# sims = emb @ q\n",
        "# pd.Series(sims, index=docs).sort_values(ascending=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mini-Übung\n",
        "\n",
        "Negation testen und diskutieren, warum BoW die Bedeutung nicht erfasst."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "title": "Notebook 4 – NLP Part 1"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}