{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2 - Symbolische KI und ML Metriken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Lernziele\n",
    "- Du laedst robust einen Klassifikationsdatensatz (Titanic bevorzugt, sonst Breast Cancer).\n",
    "- Du verstehst den Unterschied zwischen symbolischer Baseline und datengetriebenen ML-Modellen.\n",
    "- Du interpretierst Confusion Matrix, Accuracy, Precision, Recall, F1 und ROC AUC korrekt.\n",
    "- Du beobachtest systematisch den Effekt von Threshold, Klassenungleichgewicht und Zufalls-Seed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Datensatz Einblick (Titanic bevorzugt, sonst Breast Cancer Fallback)\n",
    "- Kaggle: ` /kaggle/input/titanic/train.csv ` falls vorhanden.\n",
    "- Sonst: `sklearn.datasets.load_breast_cancer`.\n",
    "- Fokus auf wenige, robuste Features und transparente Vorbereitung.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "DATA_INFO = {}\n",
    "RAW_DF = None\n",
    "X_ALL = None\n",
    "y_ALL = None\n",
    "\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    \"\"\"Laedt Titanic aus Kaggle oder faellt robust auf Breast Cancer zurueck.\"\"\"\n",
    "    titanic_path = '/kaggle/input/titanic/train.csv'\n",
    "\n",
    "    if os.path.exists(titanic_path):\n",
    "        df = pd.read_csv(titanic_path)\n",
    "        dataset_name = 'titanic'\n",
    "\n",
    "        # Wenige Features, bewusst einfach gehalten.\n",
    "        feature_cols = ['Pclass', 'Sex', 'Age', 'Fare']\n",
    "        target_col = 'Survived'\n",
    "\n",
    "        use_df = df[feature_cols + [target_col, 'SibSp', 'Parch']].copy()\n",
    "        use_df['Age'] = use_df['Age'].fillna(use_df['Age'].median())\n",
    "        use_df['Fare'] = use_df['Fare'].fillna(use_df['Fare'].median())\n",
    "\n",
    "        X = pd.get_dummies(use_df[feature_cols], columns=['Sex', 'Pclass'], drop_first=False)\n",
    "        y = use_df[target_col].astype(int)\n",
    "\n",
    "        # Fuer Korrelation/Einblick ergaenzen wir wenige numerische Hilfsspalten.\n",
    "        insight_df = use_df.copy()\n",
    "        insight_df['FamilySize'] = insight_df['SibSp'] + insight_df['Parch'] + 1\n",
    "        insight_df = pd.concat([insight_df, pd.get_dummies(insight_df['Pclass'], prefix='Pclass')], axis=1)\n",
    "        insight_df['Sex_female'] = (insight_df['Sex'] == 'female').astype(int)\n",
    "\n",
    "        info = {\n",
    "            'dataset': dataset_name,\n",
    "            'target_col': target_col,\n",
    "            'feature_cols_model': list(X.columns),\n",
    "            'insight_feature': 'Fare',\n",
    "            'scaling_used': False,\n",
    "        }\n",
    "        return df, insight_df, X, y, info\n",
    "\n",
    "    # Fallback: Breast Cancer\n",
    "    bc = load_breast_cancer(as_frame=True)\n",
    "    df = bc.frame.copy()\n",
    "    dataset_name = 'breast_cancer_fallback'\n",
    "    target_col = 'target'\n",
    "\n",
    "    # Kompaktes Feature-Set\n",
    "    feature_cols = [\n",
    "        'mean radius',\n",
    "        'mean texture',\n",
    "        'mean perimeter',\n",
    "        'mean area',\n",
    "        'mean smoothness',\n",
    "        'mean compactness',\n",
    "        'mean concavity',\n",
    "        'mean concave points',\n",
    "    ]\n",
    "\n",
    "    X_raw = df[feature_cols].copy()\n",
    "    y = df[target_col].astype(int)\n",
    "\n",
    "    # Optional standardisieren (hier aktiv fuer lineares Modell, transparent dokumentiert).\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X_raw), columns=feature_cols)\n",
    "\n",
    "    info = {\n",
    "        'dataset': dataset_name,\n",
    "        'target_col': target_col,\n",
    "        'feature_cols_model': feature_cols,\n",
    "        'insight_feature': 'mean radius',\n",
    "        'scaling_used': True,\n",
    "    }\n",
    "    return df, df.copy(), X_scaled, y, info\n",
    "\n",
    "\n",
    "RAW_DF, INSIGHT_DF, X_ALL, y_ALL, DATA_INFO = load_and_prepare_data()\n",
    "print('Dataset:', DATA_INFO['dataset'])\n",
    "print('Samples:', len(RAW_DF), '| Features fuer Modell:', len(DATA_INFO['feature_cols_model']))\n",
    "print('Scaling genutzt:', DATA_INFO['scaling_used'])\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Kurzer Datensatz-Einblick: Shape, Spalten, Missing Values.\n",
    "print('Shape:', RAW_DF.shape)\n",
    "print('\\nSpalten (erste 15):')\n",
    "print(list(RAW_DF.columns[:15]))\n",
    "\n",
    "missing = RAW_DF.isna().sum().sort_values(ascending=False).head(10)\n",
    "missing_df = pd.DataFrame({'column': missing.index, 'missing_count': missing.values})\n",
    "print('\\nMissing Values (Top 10):')\n",
    "display(missing_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot 1: Zielverteilung\n",
    "plt.figure(figsize=(5.2, 3.6))\n",
    "vc = y_ALL.value_counts().sort_index()\n",
    "plt.bar([str(i) for i in vc.index], vc.values, color=['tab:blue', 'tab:orange'])\n",
    "plt.title('Zielverteilung')\n",
    "plt.xlabel('Klasse')\n",
    "plt.ylabel('Anzahl')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot 2: Ein Feature gegen Ziel (Titanic: Fare, Cancer: mean radius)\n",
    "feat = DATA_INFO['insight_feature']\n",
    "if DATA_INFO['dataset'] == 'titanic':\n",
    "    vis_df = INSIGHT_DF[[feat, DATA_INFO['target_col']]].copy()\n",
    "    grp0 = vis_df[vis_df[DATA_INFO['target_col']] == 0][feat]\n",
    "    grp1 = vis_df[vis_df[DATA_INFO['target_col']] == 1][feat]\n",
    "else:\n",
    "    vis_df = RAW_DF[[feat, DATA_INFO['target_col']]].copy()\n",
    "    grp0 = vis_df[vis_df[DATA_INFO['target_col']] == 0][feat]\n",
    "    grp1 = vis_df[vis_df[DATA_INFO['target_col']] == 1][feat]\n",
    "\n",
    "plt.figure(figsize=(5.6, 3.8))\n",
    "plt.boxplot([grp0.values, grp1.values], labels=['target=0', 'target=1'])\n",
    "plt.title(f'{feat} nach Zielklasse')\n",
    "plt.ylabel(feat)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot 3: Korrelation Heatmap (8-12 numerische Features)\n",
    "if DATA_INFO['dataset'] == 'titanic':\n",
    "    corr_cols = ['Age', 'Fare', 'SibSp', 'Parch', 'FamilySize', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Survived']\n",
    "    corr_df = INSIGHT_DF[corr_cols].copy()\n",
    "else:\n",
    "    corr_cols = DATA_INFO['feature_cols_model'][:9] + [DATA_INFO['target_col']]\n",
    "    corr_df = RAW_DF[corr_cols].copy()\n",
    "\n",
    "corr = corr_df.corr(numeric_only=True)\n",
    "\n",
    "plt.figure(figsize=(7.2, 5.2))\n",
    "im = plt.imshow(corr.values, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=45, ha='right')\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "plt.title('Korrelation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Warm-up Spielzelle (ipywidgets): Modellwahl, Split, Threshold\n",
    "- Modelle: `rule_baseline`, `logistic_regression`, `decision_tree`.\n",
    "- Regler: `test_size`, `random_state`, `threshold`.\n",
    "- Ausgabe: Metrik-Tabelle, Confusion Matrix Heatmap, kurze Interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, y_prob=None):\n",
    "    out = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_true, y_pred, zero_division=0),\n",
    "        'roc_auc': np.nan,\n",
    "    }\n",
    "    if y_prob is not None:\n",
    "        try:\n",
    "            out['roc_auc'] = roc_auc_score(y_true, y_prob)\n",
    "        except Exception:\n",
    "            out['roc_auc'] = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def symbolic_rule_predict(X_train, X_test, info):\n",
    "    # Einfache symbolische Baseline je Datensatz.\n",
    "    if info['dataset'] == 'titanic':\n",
    "        pred = ((X_test['Sex_female'] == 1) & (X_test['Pclass_3'] == 0)).astype(int)\n",
    "        explanation = 'Regel: female und nicht Pclass_3 => Klasse 1, sonst 0'\n",
    "        return pred.values, None, explanation\n",
    "\n",
    "    # Fallback-Regel fuer Breast Cancer mit trainbasierten Schwellen.\n",
    "    radius_thr = X_train['mean radius'].quantile(0.55)\n",
    "    conc_thr = X_train['mean concavity'].quantile(0.55)\n",
    "    pred = ((X_test['mean radius'] < radius_thr) & (X_test['mean concavity'] < conc_thr)).astype(int)\n",
    "    explanation = f'Regel: mean radius<{radius_thr:.3f} und mean concavity<{conc_thr:.3f} => 1'\n",
    "    return pred.values, None, explanation\n",
    "\n",
    "\n",
    "def train_predict_ml(model_name, X_train, X_test, y_train, threshold):\n",
    "    if model_name == 'logistic_regression':\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "    elif model_name == 'decision_tree':\n",
    "        model = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "    else:\n",
    "        raise ValueError('Unbekanntes Modell')\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    y_pred = (y_prob >= threshold).astype(int) if y_prob is not None else model.predict(X_test)\n",
    "    return y_pred, y_prob\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion Matrix'):\n",
    "    plt.figure(figsize=(4.4, 3.8))\n",
    "    im = plt.imshow(cm, cmap='Blues')\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    plt.xticks([0, 1], ['pred_0', 'pred_1'])\n",
    "    plt.yticks([0, 1], ['true_0', 'true_1'])\n",
    "    plt.title(title)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j, i, str(cm[i, j]), ha='center', va='center', color='black')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "model_dd = widgets.Dropdown(\n",
    "    options=['rule_baseline', 'logistic_regression', 'decision_tree'],\n",
    "    value='rule_baseline',\n",
    "    description='model'\n",
    ")\n",
    "\n",
    "test_size_sl = widgets.FloatSlider(value=0.2, min=0.1, max=0.4, step=0.05, description='test_size', readout_format='.2f', continuous_update=False)\n",
    "random_state_sl = widgets.IntSlider(value=42, min=0, max=99, step=1, description='random_state', continuous_update=False)\n",
    "threshold_sl = widgets.FloatSlider(value=0.5, min=0.1, max=0.9, step=0.05, description='threshold', readout_format='.2f', continuous_update=False)\n",
    "run_btn = widgets.Button(description='Train and evaluate', button_style='info')\n",
    "out = widgets.Output()\n",
    "\n",
    "\n",
    "def run_eval(_):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_ALL, y_ALL,\n",
    "            test_size=test_size_sl.value,\n",
    "            random_state=random_state_sl.value,\n",
    "            stratify=y_ALL,\n",
    "        )\n",
    "\n",
    "        if model_dd.value == 'rule_baseline':\n",
    "            y_pred, y_prob, explanation = symbolic_rule_predict(X_train, X_test, DATA_INFO)\n",
    "            display(Markdown(f'**Symbolische Baseline:** {explanation}'))\n",
    "        else:\n",
    "            y_pred, y_prob = train_predict_ml(model_dd.value, X_train, X_test, y_train, threshold_sl.value)\n",
    "            display(Markdown(f'**ML Modell:** `{model_dd.value}`, threshold={threshold_sl.value:.2f}'))\n",
    "\n",
    "        m = compute_metrics(y_test, y_pred, y_prob)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        metric_df = pd.DataFrame([\n",
    "            {'metric': 'accuracy', 'value': m['accuracy']},\n",
    "            {'metric': 'precision', 'value': m['precision']},\n",
    "            {'metric': 'recall', 'value': m['recall']},\n",
    "            {'metric': 'f1', 'value': m['f1']},\n",
    "            {'metric': 'roc_auc', 'value': m['roc_auc']},\n",
    "        ])\n",
    "        display(metric_df)\n",
    "\n",
    "        plot_confusion_matrix(cm, title='Confusion Matrix')\n",
    "\n",
    "        tp = cm[1, 1]\n",
    "        fp = cm[0, 1]\n",
    "        tn = cm[0, 0]\n",
    "        fn = cm[1, 0]\n",
    "        interpretation = [\n",
    "            '- Hoher TP und TN sind gut fuer Gesamtleistung.',\n",
    "            f'- FP={fp}: falsche Alarme (Precision sinkt bei vielen FP).',\n",
    "            f'- FN={fn}: verpasste Positive (Recall sinkt bei vielen FN).',\n",
    "        ]\n",
    "        display(Markdown('**Kurzinterpretation:**\\n' + '\\n'.join(interpretation)))\n",
    "\n",
    "\n",
    "run_btn.on_click(run_eval)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    model_dd,\n",
    "    test_size_sl,\n",
    "    random_state_sl,\n",
    "    threshold_sl,\n",
    "    run_btn,\n",
    "    out,\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Datensplitting erklaert (Train Dev Test, optional CV)\n",
    "- Train: auf diesen Daten lernt das Modell seine Parameter.\n",
    "- Dev/Validation: hier werden Modellwahl und Hyperparameter abgestimmt.\n",
    "- Test: nur fuer die finale, unverzerrte Leistungsmessung.\n",
    "- Ohne saubere Trennung droht Datenleck und ueberoptimistische Bewertung.\n",
    "- Cross-Validation ersetzt optional den festen Dev-Split durch mehrere Folds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Confusion Matrix und Metriken erklaert\n",
    "### Was misst welche Metrik\n",
    "- Accuracy: Anteil aller korrekten Vorhersagen.\n",
    "- Precision: Anteil korrekter Positivvorhersagen unter allen Positivvorhersagen.\n",
    "- Recall: Anteil gefundener Positiver unter allen tatsaechlich Positiven.\n",
    "- F1: harmonisches Mittel aus Precision und Recall.\n",
    "- ROC AUC: Trennschaerfe ueber alle moeglichen Thresholds.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mini-Rechnung aus TP, FP, TN, FN mit tabellarischer Ausgabe.\n",
    "\n",
    "def metrics_from_counts(tp, fp, tn, fn):\n",
    "    acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "    prec = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    rec = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    f1 = (2 * prec * rec / (prec + rec)) if (prec + rec) else 0.0\n",
    "    return acc, prec, rec, f1\n",
    "\n",
    "# Beispielwerte, die zu einer 2x2-Matrix passen.\n",
    "TP, FP, TN, FN = 42, 8, 35, 15\n",
    "acc, prec, rec, f1 = metrics_from_counts(TP, FP, TN, FN)\n",
    "\n",
    "mini_df = pd.DataFrame([\n",
    "    {'symbol': 'TP', 'value': TP},\n",
    "    {'symbol': 'FP', 'value': FP},\n",
    "    {'symbol': 'TN', 'value': TN},\n",
    "    {'symbol': 'FN', 'value': FN},\n",
    "    {'symbol': 'accuracy', 'value': round(acc, 4)},\n",
    "    {'symbol': 'precision', 'value': round(prec, 4)},\n",
    "    {'symbol': 'recall', 'value': round(rec, 4)},\n",
    "    {'symbol': 'f1', 'value': round(f1, 4)},\n",
    "])\n",
    "display(mini_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Aufsteigende Erweiterungen\n",
    "- a) Klassenungleichgewicht: Zielverteilung zeigt, warum Accuracy taeuschen kann.\n",
    "- b) Threshold-Tradeoff: Precision/Recall verschieben sich mit dem Grenzwert.\n",
    "- c) Multi-Seed: Stabilitaet ueber mehrere Zufallssplits statt Einzelwert.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 6a) Klassenungleichgewicht kurz sichtbar machen.\n",
    "class_counts = y_ALL.value_counts().sort_index()\n",
    "ratio = class_counts.min() / class_counts.max()\n",
    "\n",
    "plt.figure(figsize=(5.2, 3.6))\n",
    "plt.bar([str(i) for i in class_counts.index], class_counts.values, color=['tab:blue', 'tab:orange'])\n",
    "plt.title('Klassenungleichgewicht (Zielverteilung)')\n",
    "plt.xlabel('Klasse')\n",
    "plt.ylabel('Anzahl')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Min/Max Verhaeltnis: {ratio:.3f}')\n",
    "print('Hinweis: Bei starkem Ungleichgewicht kann hohe Accuracy trotz schlechter Recall entstehen.')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 6b) Threshold-Tradeoff als Tabelle (auf Logistic Regression, falls verfuegbar).\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ALL, y_ALL, test_size=0.2, random_state=42, stratify=y_ALL)\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "proba = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "rows = []\n",
    "for thr in [0.2, 0.35, 0.5, 0.65, 0.8]:\n",
    "    pred = (proba >= thr).astype(int)\n",
    "    rows.append({\n",
    "        'threshold': thr,\n",
    "        'precision': precision_score(y_test, pred, zero_division=0),\n",
    "        'recall': recall_score(y_test, pred, zero_division=0),\n",
    "        'f1': f1_score(y_test, pred, zero_division=0),\n",
    "    })\n",
    "\n",
    "tradeoff_df = pd.DataFrame(rows)\n",
    "display(tradeoff_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 6c) Multi-Seed-Evaluation ueber 5 Seeds mit Mittelwerten.\n",
    "\n",
    "def evaluate_one_seed(seed):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_ALL, y_ALL, test_size=0.2, random_state=seed, stratify=y_ALL\n",
    "    )\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    proba = model.predict_proba(X_test)[:, 1]\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "    m = compute_metrics(y_test, pred, proba)\n",
    "    return {\n",
    "        'seed': seed,\n",
    "        'accuracy': m['accuracy'],\n",
    "        'precision': m['precision'],\n",
    "        'recall': m['recall'],\n",
    "        'f1': m['f1'],\n",
    "        'roc_auc': m['roc_auc'],\n",
    "    }\n",
    "\n",
    "seed_rows = [evaluate_one_seed(s) for s in [0, 1, 2, 3, 4]]\n",
    "seed_df = pd.DataFrame(seed_rows)\n",
    "mean_row = {'seed': 'mean'}\n",
    "for c in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
    "    mean_row[c] = seed_df[c].mean()\n",
    "\n",
    "result_df = pd.concat([seed_df, pd.DataFrame([mean_row])], ignore_index=True)\n",
    "display(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Mini Leitfaden (7 bis 10 Minuten)\n",
    "- Minute 0-1: Datensatzquelle pruefen (Titanic oder Fallback) und Zielverteilung ansehen.\n",
    "- Minute 1-3: Warm-up mit `rule_baseline` laufen lassen, Metriken lesen.\n",
    "- Minute 3-5: auf `logistic_regression` wechseln und Confusion Matrix vergleichen.\n",
    "- Minute 5-7: threshold variieren und Precision/Recall-Tradeoff beobachten.\n",
    "- Minute 7-9: Erweiterung Multi-Seed lesen und Stabilitaet statt Einzelwert einordnen.\n",
    "- Minute 9-10: festhalten, wann symbolische Baseline reicht und wann ML noetig ist.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Uebungen\n",
    "1. Passe die symbolische Titanic-Regel leicht an und pruefe den Effekt auf Precision/Recall.\n",
    "2. Suche einen Threshold mit Recall > 0.90 und notiere den Precision-Verlust.\n",
    "3. Vergleiche `decision_tree` und `logistic_regression` bei identischem Split.\n",
    "4. Erhoehe test_size auf 0.4 und bewerte die Stabilitaet der Metriken.\n",
    "5. Erweitere die Multi-Seed-Tabelle um Standardabweichungen.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31259,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
